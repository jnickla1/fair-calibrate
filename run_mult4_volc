#!/bin/bash
#SBATCH -J FAIRc_Nv
#SBATCH -t 10:00:00
#SBATCH -N 1
#SBATCH -n 48
#SBATCH --account=epscor-condo
#SBATCH --array=25
###SBATCH --mem-per-cpu=8gb

# Use '%A' for array-job ID, '%J' for job ID and '%a' for task ID
#####SBATCH -e arrayjob-%a.err
#SBATCH -o arrVolc-%a.out

echo "Starting job $SLURM_ARRAY_TASK_ID on $HOSTNAME"

# usage: ./run

eval "$(conda shell.bash hook)"
conda activate fair-calibrate
module load r
module load parallel
# Don't forget to set your environment variables in .env
if [ -f .env ]
then
  export $(cat .env | xargs)
fi

# Base path to your fair-calibrate input tree
script_dir=$PWD
export base_dir="${script_dir}/input/fair-${FAIR_VERSION}/v${CALIBRATION_VERSION}/${CONSTRAINT_SET}"

unset ENSEMBLE_RUN
export ENSEMBLE_RUN=$SLURM_ARRAY_TASK_ID


unset CUTOFF_YEAR
start=$SECONDS
cd "${base_dir}/sampling"
"./09_run-fair-ssp-prior-ensemble-ebm3-intvar.py" || { echo "ERROR in final sampling for cutoff"; exit 1; }
echo $(( SECONDS - start ))
#takes about 8600s for 40
echo "Done with sampling"

